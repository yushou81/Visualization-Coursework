# 第1组-作业1-内部威胁可视分析-陈起刚(8209230611)-夏瑜麒(0110230114)-邱宇轩(8209230608)-赵洋毅(8209230610)

> 项目背景：我们复现《中国信息可视分析挑战赛 2018 - 挑战 1》（HighTech 内部威胁场景），参考《2018年数据可视分析挑战赛-挑战1-题目描述.docx》与官方评审指南《ChinaVis 2018 数据可视分析挑战赛-挑战1-参考答案.docx》，围绕 2017 年 11 月 30 天的登录、网页、TCP、邮件与打卡日志构建工作流。本报告按照“数据下载→数据理解→数据过滤→数据处理”四个阶段说明当前进展，并在各小节标注主要负责同学。

## 0 组织与分工
- 组长：陈起刚（8209230611），统筹四个阶段的质量与节奏，把控数据安全。
- 组员：夏瑜麒（0110230114）、邱宇轩（8209230608）、赵洋毅（8209230610）、石文翔（8209230602），分别负责多源数据理解、过滤策略、处理脚本与特征验证。
- 项目管理方式：每周一次例会 + 两次短同步，使用飞书任务看板将四个阶段拆分为 12 个子任务，状态实时更新。

| 阶段 | 责任人 | 当前状态 | 输出物 |
| --- | --- | --- | --- |
| 数据下载 | 陈起刚 | ✅ 完成 | 数据镜像、校验报告 |
| 数据理解 | 夏瑜麒（主）、陈起刚、石文翔 | ✅ 完成 | 字段字典、关系图、问题清单 |
| 数据过滤 | 邱宇轩（主）、赵洋毅 | 🔄 迭代中 | 筛选 SQL、过滤日志、数据覆盖率统计 |
| 数据处理 | 赵洋毅（主）、夏瑜麒、石文翔 | 🔄 迭代中 | 清洗脚本、特征表、处理耗时分析 |

---

## 1 数据下载（陈起刚）
这一阶段聚焦原始数据的获取、校验和目录整理，确保团队成员都能在本仓库中使用相同的 2017 年 11 月原始 CSV。

### 1.1 GitHub release 拉取
- 直接从 GitHub 仓库 `csuvis/InsiderThreatData` 下载（或 `git clone`）官方发布的 ITD-2018 数据包，并保存在 `backend/InsiderThreatData/ITD-2018 Data Set/`，以便与后端脚本位于同一目录。
- 同步存放官方说明文档《Data User Guide.pdf》《ChinaVis Data Challenge 2018 Reviewers Guide.pdf》，用于核对字段含义与竞赛要求。

### 1.2 目录结构与示例
- 数据以“天”为粒度存放，示例路径为 `backend/InsiderThreatData/ITD-2018 Data Set/2017-11-01/checking.csv`、`.../logon.csv`、`.../weblog.csv` 等，对应题目描述中的打卡、登录、网页、邮件、TCP 日志。
- 直接检查 `checking.csv` 可看到字段 `id,day,checkin,checkout`，而 `backend/InsiderThreatData/README.md` 记录了各 CSV 列表与来源。
- 为方便前端演示，我们将部分处理后的结果（如 `backend/app/json_statics/1284.json` 的个人画像、`weblog_record_groups.json` 的部门聚合）存放在仓库中，便于离线展示。

### 1.3 版本记录
- 当前数据沿用官方 release，没有额外制作 NAS/对象存储镜像，所有修改都通过 Git diff 可追踪；如需重新获取，只需再次从 GitHub 下载覆盖。
- 数据导入与重跑步骤记录在 `backend/docs/数据导入脚本使用说明.md`，说明了如何指定数据根目录、批量大小以及数据库连接参数。

![插图占位符-下载流程图](images/download-flow.png)
<!-- TODO: 插入包含“GitHub release → backend/InsiderThreatData → scripts/import_dataset.py”通路的流程图。 -->

---

## 2 数据理解（夏瑜麒）
重点拆解各数据域的语义、字段含义及潜在业务问题，为后续过滤与处理提供依据。

### 2.1 数据全景速览（夏瑜麒）
- 借助 `DuckDB` 快速抽样 1% 日志，统计 5 个主子集（login、weblog、tcpLog、email、checking）的规模、时间跨度、关键字段完整度。
- 对照官方题目提供的数据说明，确认我们的快照覆盖 2017-11-01 至 2017-11-30 的 30 天监控数据，字段含义与描述文档一致。
- 将统计结果同步到项目看板（供 Step5 的视图设计使用），以便在 Word/视频中引用真实数字。

![插图占位符-数据全景概览](images/data-overview.png)
<!-- TODO: 插入“各子数据集事件数量/时间跨度”的堆叠条形图或旭日图。 -->

### 2.2 人员与组织语义（陈起刚、石文翔）
- 解析仓库内的 `backend/部门职位.csv`，结合 `backend/app/json_statics/ip_id.json` 建立“员工 ID → 邮箱 → 部门 → 职位 → IP”链条，这些字段正是 `scripts/import_dataset.py` 导入 `link`、`department` 表时的输入数据。
- 组织结构采用“管理、人力、财务、研发 1-3”六类编码（见 `import_dataset.py` 中 `_guess_depart_code`），石文翔据此绘制组织结构草图，标注岗位等级（`_derive_level` 推算）和当前任务归属。
- 借助 `backend/app/json_statics/1284.json` 这类静态画像，验证组织信息在前端可视化中的呈现方式，确保 Word 答卷中的组织图能直接引用真实字段。

### 2.3 行为日志语义（夏瑜麒）
- 针对五类日志（login、weblog、tcpLog、email、checking），逐一比对 `backend/InsiderThreatData/ITD-2018 Data Set` 中的 CSV 头部和 `backend/docs/数据库操作文档.md` 的建表语句，形成字段字典。
- 针对登录/网页日志，重点记录 `sip/dip/dport/proto/time` 组合；邮件日志关注 `sender/receiver/subject`；TCP 日志关注 `uplink_length/downlink_length`；打卡日志关注 `checkin/checkout`。
- 初步识别 3 种有代表性的行为模式：① 周末登录 + TCP 大流量；② 打卡缺勤 + VPN 访问（可由 login + checking 交叉）；③ 高频访问外部域名 + 邮件外发。

### 2.4 问题清单与假设（夏瑜麒、陈起刚）
- 确立三类核心问题：数据泄露路径、异常通信对、敏感文件外发。
- 结合实际 CSV 字段整理映射表，直接内嵌在本报告以便后续复用：

| 问题 | 关键字段 | 数据来源 | 辅助字段 |
| --- | --- | --- | --- |
| 数据泄露路径 | `sender`,`receiver`,`subject`,`uplink_length`,`downlink_length` | `email.csv`,`tcpLog.csv` | `link.ip`,`department`（来自 `部门职位.csv`） |
| 异常通信对 | `sip`,`dip`,`host`,`proto`,`state` | `weblog.csv`,`login.csv` | `checking.csv` 的出勤结果 |
| 敏感文件外发 | `subject` 中含“方案/源码”，`time` 落在非工作时段 | `email.csv` | `checking.csv` 的 `checkin/checkout`、`link` 中的岗位级别 |

![插图占位符-问题矩阵示意](images/question-matrix.png)
<!-- TODO: 插入展示“问题类别 vs. 关键字段 vs. 数据源”的热力图或表格截图。 -->

### 2.5 题目要求映射（夏瑜麒、石文翔）
- 依据官方题目描述的三大任务（组织结构、正常模式、异常事件），分别绑定数据资产：组织结构引用 `backend/部门职位.csv` + `link` 表；正常模式通过 `weblog_record_groups.json`、`checking.csv` 描述部门行为；异常事件由 login/email/tcpLog 的交叉过滤提供证据。
- 石文翔维护“题目要求→可视视图→输入字段→输出截图”的检查清单，目前记录在共享文档中，将在导出 Word 时同步引用本仓库内的 JSON/CSV 示例。

---

## 3 数据过滤（邱宇轩）
在充分理解数据后，结合仓库中的脚本与静态 JSON，构建面向竞赛题目的过滤与聚合策略。

### 3.1 数据导入与初筛脚本（邱宇轩）
- 直接使用 `backend/scripts/import_dataset.py` 的 `ChinavisImporter` 导入 CSV。脚本逐日遍历 `backend/InsiderThreatData/ITD-2018 Data Set/2017-11-*`，通过 `_read_csv` 自动尝试 `utf-8-sig` 与 `gb18030`，过滤编码异常。
- `_load_reference_tables` 阶段会忽略缺少 IP 映射的员工（脚本输出 “Skipping user … no IP mapping found”），确保进入数据库的记录都能与 `link`/`department` 表关联。
- 导入 login/tcpLog/email/checking 时统一使用 `_to_int`、`_parse_dt` 处理字段，异常值直接落为 `NULL`，而不是杜撰补全数据。

### 3.2 域名与行为标签过滤（邱宇轩、石文翔）
- `DomainClassifier` 根据关键字将域名划分为“办公/开发/技术/娱乐/购物/招聘/搜索/赌博”，`_handle_weblog_side_effects` 会把无法分类的域名排除并记录 canonical domain。
- 统计结果写入 `weblog_record` 表后，导出为 `backend/app/json_statics/weblog_record_groups.json`，可直接看到人力、财务、研发不同部门在“办公、娱乐”等标签上的访问量，用于识别部门层面的异常。

### 3.3 出勤与访问交叉筛选（邱宇轩）
- `checking2`（由 `checking.csv` 导入）提供每日出勤；我们通过 SQL 将其与 login/weblog 关联，筛出“缺勤但有登录”“加班时段访问非办公域名”等候选事件，直接对应挑战题目中的异常模式。
- `backend/app/json_statics/1284.json` 等静态画像用于人工复核，确保过滤结果与真实员工的时间线一致。

### 3.4 异常事件线索墙（邱宇轩、石文翔）
- 参照官方参考答案列举的事件（Data leakage、Stepping stone event、VPN remote access 等），将过滤条件整理为 checklist，如“TCP uplink >10MB 且紧随邮件外发”“23:00 后连续登录失败”等。
- 石文翔负责核对每条线索的证据来源（login/email/tcpLog/checking），确保最终提交的异常案例不少于 5 个，并与题目描述的业务背景吻合。

---

## 4 数据处理（赵洋毅）
聚焦数据清洗、特征构造与落地到可视化前的中间表。

### 4.1 清洗与入库流水线（赵洋毅）
- 仍以 `backend/scripts/import_dataset.py` 为核心：`_load_mappings`→`_load_reference_tables`→`_ingest_email/weblog/login/tcplog/checking`→`_persist_domain_helpers`→`_persist_weblog_record`。流程既完成清洗（时间格式、端口数值、域名归一化），也将结果落地 MySQL。
- 通过 `--batch-size` 参数（默认 2000）控制一次性写入条数，保证导入过程中内存稳定；脚本输出日志 `"[import] Importing login records"`，便于在终端直接监控进度。
- 根据竞赛要求，我们把入库结果划分为三类：`department/link`（组织结构快照）、`weblog_record`（部门行为基线）、`email/login/tcplog/checking2`（异常证据链），便于 Word/视频引用。

![插图占位符-数据处理流水线图](images/processing-pipeline.png)
<!-- TODO: 插入展示“原始 CSV → import_dataset.py → MySQL + json_statics”流程的泳道图。 -->

### 4.2 特征与指标构建（夏瑜麒、石文翔）
- 依托数据库中的 `weblog_record` 与静态 JSON，构建 3 类指标：
  1. 行为频率：同一员工在 `weblog_record` 中各标签的访问量（直接源自 `DomainClassifier` 的统计）。
  2. 时序偏离：`checking2` 的 `checkin/checkout` 与 login 记录的时间差。
  3. 网络/文件风险：`tcpLog` 的上下行长度与 email 的主题关键词。
- 指标以 SQL/脚本的方式写入 JSON（如 `1284.json`）供前端展示；石文翔负责核对这些数值是否能直接支撑“正常模式/异常事件”两大问题。

### 4.3 处理质量监控（赵洋毅）
- `_read_csv` 内建双编码兜底（`utf-8-sig`→`gb18030`），若两者都失败才抛出异常，确保中文字段不会被破坏。
- `_to_int`、`_parse_dt` 会在解析失败时返回 `None` 并记录日志，避免出现伪造数据；`_handle_weblog_side_effects` 中的 canonical domain 保证不同写法的域名被统一。
- 处理完成后输出的 `weblog_record_groups.json`、`ip_id.json` 等静态文件可直接与原始 CSV 对比校验，避免“指标脱离原始数据”的风险。

![插图占位符-质量监控看板](images/quality-dashboard.png)
<!-- TODO: 插入展示“导入日志 vs. 字段空值数量”的折线图或仪表板截图。 -->

---

## 5 下一步计划
1. **数据到图形映射（11 月第 3 周）**：夏瑜麒牵头定义视图组合（网络流、桑基图、堆叠时间轴），并与前端确认接口字段。
2. **美化与装饰（11 月第 4 周）**：陈起刚主导统一配色、字号与图例；同时引入暗/亮主题切换。
3. **交互设计（12 月上旬）**：邱宇轩与赵洋毅合作实现“多维刷选 + 时间窗口联动”，并将过滤条件回写至后端。
4. **竞赛交付准备（与石文翔同步）**：石文翔负责将 Markdown 导出 Word，并对照挑战 1 题目与官方参考答案，检查“组织结构、正常模式、异常事件”三部分是否齐备，同时规划 5 分钟讲解视频脚本。

---

## 6 提交物清单
- 本 Markdown 文档（可直接导入 Word），包含图文结构与责任说明。
- `backend/docs/数据导入脚本使用说明.md`、`backend/docs/数据库操作文档.md`（包含数据库建表与导入步骤）。
- `backend/app/json_statics/` 下的示例 JSON（如 `1284.json`、`weblog_record_groups.json`），用于展示当前特征计算成果。
- 题目与参考资料：`2018年数据可视分析挑战赛-挑战1-题目描述.docx`、`ChinaVis 2018 数据可视分析挑战赛-挑战1-参考答案.docx`，供老师核对我们对题意的理解。

> 如需导出 Word，可在 Typora、VS Code 或 Pandoc 中打开本文件，直接另存为 `.docx`。插图处已留出占位符，请按注释补充对应的可视化截图或示意图。
